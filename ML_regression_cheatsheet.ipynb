{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Regression Cheetsheet\n",
    "\n",
    "1. [Linear Regression](#linear)<br>\n",
    "2. [Regularized Regression](#regularized)<br>\n",
    "    2.1 [LASSO (L1 Norm)](#lasso)<br>\n",
    "    2.2 [RIDGE (L2 Norm)](#ridge)<br>\n",
    "    2.3 [ELASTIC-NET](#elastic)<br>\n",
    "3. [Random Forrest Regression](#rf)<br>\n",
    "4. [Gradient Boosting](#gb)<br>\n",
    "5. [XGBoost Regression](#xgboost)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Display all rows and columns\n",
    "pd.set_option( 'display.max_columns', None )\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Boston data\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston() # sklearn.utils.Bunch datatype\n",
    "X = pd.DataFrame( data.data, columns=data.feature_names ) # feature df\n",
    "y = data.target # target ['MEDV']\n",
    "\n",
    "print( data.DESCR ) #view description of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Preprocessing Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify (n-1) categorical feature\n",
    "def prepro_dummy( X_mat ):\n",
    "    df = X_mat.copy()\n",
    "    rad = pd.get_dummies(df['RAD'],      # dummy RAD feature\n",
    "                         prefix='RAD',       # prefix of new columns\n",
    "                         prefix_sep='__')    # separates prefix and rest of name\n",
    "    rad = rad.drop( 'RAD__1.0', axis=1 )   # want n-1 dummy features to minimize sparcity\n",
    "    df = pd.concat( [df, rad], axis=1 )    # combine original and dummified DFs\n",
    "    df.drop( 'RAD', axis=1, inplace=True ) # remove original RAD categorical feature\n",
    "\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ZN to bool due to imbalance\n",
    "def prepro_ZN( X_mat ):\n",
    "    df = X_mat.copy()\n",
    "    df['ZN'] = df['ZN'].apply( lambda x: 1 if x > 0 else 0 )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove CHAS feature\n",
    "def prepro_CHAS( X_mat ):\n",
    "    df = X_mat.copy()\n",
    "    df.drop('CHAS', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Scale of Columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def prepro_scale( X_mat ):\n",
    "    df = X_mat.copy()                            # copy data\n",
    "    scale = StandardScaler()                     # instantiate model\n",
    "    trans = scale.fit_transform( df )            # scale feature df\n",
    "    df = pd.DataFrame( trans, columns=df.columns ) # convert to df\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine to preprocessing pipleline for future testing\n",
    "def preprocess_data( X_mat ):\n",
    "    df = X_mat.copy()\n",
    "    df = prepro_dummy(df) # dummify categorical data\n",
    "    df = prepro_ZN(df)    # convert ZN to boolean\n",
    "    df = prepro_CHAS(df)  # remove CHAS feature\n",
    "    df = prepro_scale(df) # scale feature matrix\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split data for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,             \n",
    "                                                    y,              \n",
    "                                                    test_size = 0.3,  # size of test split\n",
    "                                                    random_state = 0) # RandomState instance same each time\n",
    "\n",
    "# Process feature data\n",
    "x_train_pro = preprocess_data( x_train )\n",
    "x_test_pro = preprocess_data( x_test )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"linear\"></a></p>\n",
    "\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear = LinearRegression()                  # instantiate general model\n",
    "linear = linear.fit( x_train_pro, y_train )  # fit model with data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate Model Attributes**\n",
    "\n",
    "`linear.score(X, y)` = coeff of determination (R^2)\n",
    "\n",
    "`linear.coef_` = model feature coefficients\n",
    "\n",
    "`linear.intercept_` = y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model Performance/Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION\n",
      "--------------------------------------\n",
      "Train RMSE: 4.47\n",
      "Test RMSE: 5.21\n",
      "\n",
      "Train R^2: 0.76\n",
      "Test R^2: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "# Predict train and test targets\n",
    "y_pred_train = linear.predict( x_train_pro )   # predict training target\n",
    "y_pred_test = linear.predict( x_test_pro )     # predict test target\n",
    "\n",
    "# Print results\n",
    "print('LINEAR REGRESSION')\n",
    "print('--------------------------------------')\n",
    "print('Train RMSE: %0.2f' % np.sqrt( MSE(y_train, y_pred_train) ))\n",
    "print('Test RMSE: %0.2f' % np.sqrt( MSE(y_test, y_pred_test) ))\n",
    "print(\"\")\n",
    "print('Train R^2: %0.2f' % linear.score(x_train_pro, y_train))\n",
    "print('Test R^2: %0.2f' % linear.score(x_test_pro, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE of train set << test set**\n",
    "\n",
    "*Model has high variance and low bias*\n",
    "- High variance = model is not generalizable\n",
    "- Low bias = model captures noise as the true relationship\n",
    "    \n",
    "*Want to introduct more bias in model*\n",
    "- Reduce variance (ie. overfit)\n",
    "- Improve RMSE_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"regularized\"></a></p>\n",
    "\n",
    "## 2. Regularized Regression\n",
    "- Slope of model describes how sensitive model is to input feature\n",
    "    - Penalize slopes to introduce bias (thus reducing variance)\n",
    "    \n",
    "- Amount of penalization determined by hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"lasso\"></a></p>\n",
    "\n",
    "### 2.1 Lasso (L1 Norm) Regularized Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create LASSO Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate general model\n",
    "lasso = Lasso()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Grid Search to tune hyperparameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 10],             # penalization term\n",
    "              'fit_intercept': [True, False]}            # calculate intercept or not (beta0)\n",
    "\n",
    "# Instantiate GridSearchCV model\n",
    "grid = GridSearchCV(estimator=lasso,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=5)\n",
    "\n",
    "# Fit training data to GridSearchCV model\n",
    "grid.fit( x_train_pro, y_train)\n",
    "\n",
    "# Assign tuned parameters to model \n",
    "lasso = grid.best_estimator_ # best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate GridSearch Attributes**\n",
    "\n",
    "`grid.best_estimator_` = return all parameters of best model\n",
    "\n",
    "`grid.best_params_` = returns only params searched (ie. param_grid features)\n",
    "\n",
    "`grid.best_estimator_.coef_` = returns best model's coeffs\n",
    "\n",
    "`grid.best_estimator_.intercept` = returns best model's intercept\n",
    "\n",
    "`grid.best_score_` = returns best R^2 score (able to choose metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'fit_intercept': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate Model Attributes**\n",
    "\n",
    "`lasso.score(X, y)` = coeff of determination (R^2)\n",
    "\n",
    "`lasso.coef_` = model feature coefficients\n",
    "\n",
    "`lasso.intercept_` = y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeff_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>3.722896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.964789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>0.204690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>0.047251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>0.007958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.012944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.021431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.039925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.113118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.523924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.852690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.233704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coeff_value\n",
       "RM          3.722896\n",
       "CHAS        0.964789\n",
       "RAD         0.204690\n",
       "ZN          0.047251\n",
       "B           0.007958\n",
       "TAX        -0.012944\n",
       "AGE        -0.021431\n",
       "INDUS      -0.039925\n",
       "CRIM       -0.113118\n",
       "LSTAT      -0.523924\n",
       "PTRATIO    -0.852690\n",
       "DIS        -1.233704"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = x_train_pro.columns.tolist() # list features\n",
    "coefs_df = pd.DataFrame(lasso.coef_, index=cols, columns=['coeff_value']) # df of coefficients\n",
    "coefs_df[ coefs_df['coeff_value'] !=0 ].sort_values(by='coeff_value',ascending=False) # important features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model Performance/Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO (L1) REGRESSION\n",
      "--------------------------------------\n",
      "Train RMSE: 4.57\n",
      "Test RMSE: 5.37\n",
      "\n",
      "Train R^2: 0.75\n",
      "Test R^2: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "# Predict train and test targets\n",
    "y_pred_train = lasso.predict( x_train_pro )   # predict training target\n",
    "y_pred_test = lasso.predict( x_test_pro )     # predict test target\n",
    "\n",
    "# Print results\n",
    "print('LASSO (L1) REGRESSION')\n",
    "print('--------------------------------------')\n",
    "print('Train RMSE: %0.2f' % np.sqrt( MSE(y_train, y_pred_train) ))\n",
    "print('Test RMSE: %0.2f' % np.sqrt( MSE(y_test, y_pred_test) ))\n",
    "print(\"\")\n",
    "print('Train R^2: %0.2f' % lasso.score(x_train_pro, y_train))\n",
    "print('Test R^2: %0.2f' % lasso.score(x_test_pro, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"ridge\"></a></p>\n",
    "\n",
    "### 2.2 Ridge (L2 Norm) Regularized Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create RIDGE Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Instantiate general model\n",
    "ridge = Ridge()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Grid Search to tune hyperparameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 10],             # penalization term\n",
    "              'fit_intercept': [True, False]}            # calculate intercept or not (beta0)\n",
    "\n",
    "# Instantiate GridSearchCV model\n",
    "grid = GridSearchCV(estimator=ridge,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=5)\n",
    "\n",
    "# Fit training data to GridSearchCV model\n",
    "grid.fit(x_train_pro, y_train)\n",
    "\n",
    "# Assign tuned parameters to model \n",
    "ridge = grid.best_estimator_ # best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate GridSearch Attributes**\n",
    "\n",
    "`grid.best_estimator_` = return all parameters of best model\n",
    "\n",
    "`grid.best_params_` = returns only params searched (ie. param_grid features)\n",
    "\n",
    "`grid.best_estimator_.coef_` = returns best model's coeffs\n",
    "\n",
    "`grid.best_estimator_.intercept` = returns best model's intercept\n",
    "\n",
    "`grid.best_estimator_.score` = returns best R^2 score (able to choose metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'fit_intercept': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate Model Attributes**\n",
    "\n",
    "`ridge.score(X, y)` = coeff of determination (R^2)\n",
    "\n",
    "`ridge.coef_` = model feature coefficients\n",
    "\n",
    "`ridge.intercept_` = y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model Performance/Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE (L2) REGRESSION\n",
      "--------------------------------------\n",
      "Train RMSE: 4.47\n",
      "Test RMSE: 5.22\n",
      "\n",
      "Train R^2: 0.76\n",
      "Test R^2: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "# Predict train and test targets\n",
    "y_pred_train = ridge.predict( x_train_pro )   # predict training target\n",
    "y_pred_test = ridge.predict( x_test_pro )     # predict test target\n",
    "\n",
    "# Print results\n",
    "print('RIDGE (L2) REGRESSION')\n",
    "print('--------------------------------------')\n",
    "print('Train RMSE: %0.2f' % np.sqrt( MSE(y_train, y_pred_train) ))\n",
    "print('Test RMSE: %0.2f' % np.sqrt( MSE(y_test, y_pred_test) ))\n",
    "print(\"\")\n",
    "print('Train R^2: %0.2f' % ridge.score(x_train_pro, y_train))\n",
    "print('Test R^2: %0.2f' % ridge.score(x_test_pro, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"elastic\"></a></p>\n",
    "\n",
    "### 2.3 Elastic-Net Regularized Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create ELASTIC NET Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Instantiate general model\n",
    "elastic = ElasticNet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Grid Search to tune hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define possible hyperparameter values\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 10],             # penalization term\n",
    "              'l1_ratio': [0, 0.1, 0.25, 0.5, 0.75, 1],  # penalization weight (l1=0, l2=1)\n",
    "              'fit_intercept': [True, False]}            # calculate intercept or not (beta0)\n",
    "\n",
    "# Instantiate GridSearchCV model\n",
    "grid = GridSearchCV(estimator = elastic,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = 5)\n",
    "\n",
    "# Fit training data to GridSearchCV model\n",
    "grid.fit( x_train_pro, y_train) # will run permutation of hyperparameter values\n",
    "\n",
    "# Assign tuned parameters to ElasticNet model \n",
    "elastic = grid.best_estimator_ # assign best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate GridSearch Attributes**\n",
    "\n",
    "`grid.best_estimator_` = returns best model\n",
    "\n",
    "`grid.best_params_` = returns params of best model\n",
    "\n",
    "`grid.best_estimator_.coef_` = returns best model's coefficients\n",
    "\n",
    "`grid.best_estimator_.intercept` = returns best model's intercept\n",
    "\n",
    "`grid.best_estimator_.score` = returns best model's scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate Model Attributes**\n",
    "\n",
    "`elastic.score(X, y)` = coeff of determination (R^2)\n",
    "\n",
    "`elastic.coef_` = model feature coefficients\n",
    "\n",
    "`elastic.intercept_` = y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model Performance/Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic-Net REGRESSION\n",
      "--------------------------------------\n",
      "Train RMSE: 4.60\n",
      "Test RMSE: 5.38\n",
      "\n",
      "Train R^2: 0.75\n",
      "Test R^2: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score  \n",
    "\n",
    "# Predict train and test targets\n",
    "y_pred_train = elastic.predict( x_train_pro )   # predict training target\n",
    "y_pred_test = elastic.predict( x_test_pro )     # predict test target\n",
    "\n",
    "# Print results\n",
    "print('Elastic-Net REGRESSION')\n",
    "print('--------------------------------------')\n",
    "print('Train RMSE: %0.2f' % np.sqrt( MSE(y_train, y_pred_train) ))\n",
    "print('Test RMSE: %0.2f' % np.sqrt( MSE(y_test, y_pred_test) ))\n",
    "print(\"\")\n",
    "print('Train R^2: %0.2f' % elastic.score(x_train_pro, y_train))\n",
    "print('Test R^2: %0.2f' % elastic.score(x_test_pro, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"rf\"></a></p>\n",
    "\n",
    "### 3. Random Forrest Regression\n",
    "\n",
    "Links:\n",
    "- [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/)\n",
    "- [RF Boston Housing](https://towardsdatascience.com/predicting-housing-prices-using-a-scikit-learns-random-forest-model-e736b59d56c5)\n",
    "\n",
    "Background:\n",
    "- Ensemble algorithm\n",
    "    - Combines multiple decisions trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Random Forrest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate general model\n",
    "rforrest = RandomForestRegressor(criterion='mse',  # measure quality of split\n",
    "                                 bootstrap = True, # if false, all data used to build each tree\n",
    "                                 oob_score = True, # use OOB samples to estimate R^2 on unseen data\n",
    "                                 n_jobs=-1)        # dispatch n-1 CPUs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model (No Hyperparameters)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Baseline Model\n",
      "--------------------------------------\n",
      "Train RMSE: 1.22\n",
      "Train R^2: 0.98\n"
     ]
    }
   ],
   "source": [
    "rforrest.fit(x_train, y_train) #fit data to base model\n",
    "y_pred_train = rforrest.predict(x_train)\n",
    "\n",
    "print('Random Forrest Baseline Model')\n",
    "print('--------------------------------------')\n",
    "print('Train RMSE: %0.2f' % np.sqrt( MSE(y_train, y_pred_train) ))\n",
    "print('Train R^2: %0.2f' % rforrest.score( x_train_pro, y_train ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Grid Search to tune hyperparameters**\n",
    "\n",
    "`max_depth (def=None)` - number of nodes in tree (too large, overfit)\n",
    "\n",
    "`min_sample_split (def=2)` - min # observations required for split (too small, overfit)\n",
    "\n",
    "`max_leaf_nodes (def=2)` - num. terminal nodes (too large, overfit)\n",
    "\n",
    "`min_samples_leaf (def=1)` - min num. samples in leaf after splitting (like terminal nodes)\n",
    "\n",
    "`n_estimators (def=100)` - number of trees in forrest\n",
    "\n",
    "`max_sample (def=None)` - frac. of dataset given to any individual tree\n",
    "\n",
    "`max_features (def=auto)` - num. features provided to each tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#GridSearchCV searched ALL permutations (computationally expensive)\n",
    "\n",
    "# Define possible hyperparameter values\n",
    "param_grid = {'n_estimators': [*range(100,5000,200)],  # n trees per forrest\n",
    "              'max_features': ['auto', 'sqrt','log2'], # max features considered at split\n",
    "              'max_depth': [*range(10,60,10)],         # max nodes in tree\n",
    "              'min_samples_split': [*range(2,22,2)],   # min samples required for node split\n",
    "              'min_samples_leaf': [*range(1,23,3)]}    # min samples at each leaf\n",
    "    \n",
    "\n",
    "# Instantiate RandomizedSearchCV model\n",
    "search = RandomizedSearchCV(estimator = rforrest,\n",
    "                            param_distributions = param_grid,\n",
    "                            n_iter = 50,\n",
    "                            cv = 3,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=True,\n",
    "                            random_state=42)\n",
    "\n",
    "# Fit training data to GridSearchCV model\n",
    "search.fit( x_train_pro, y_train ) # will run permutation of hyperparameter values\n",
    "\n",
    "# Assign tuned parameters to ElasticNet model \n",
    "rforrest = search.best_estimator_ # assign best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate RandomSearchCV Attributes**\n",
    "\n",
    "`search.best_estimator_` = returns best model\n",
    "\n",
    "`search.best_params_` = returns params of best model\n",
    "\n",
    "`search.best_estimator_.coef_` = returns best model's coefficients\n",
    "\n",
    "`search.best_estimator_.intercept` = returns best model's intercept\n",
    "\n",
    "`search.best_estimator_.score` = returns best model's scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 4100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 50}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate Model Attributes**\n",
    "\n",
    "[Link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model Performance/Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic-Net REGRESSION\n",
      "--------------------------------------\n",
      "Train RMSE: 1.22\n",
      "Test RMSE: 3.78\n",
      "\n",
      "Train R^2: 0.98\n",
      "Test R^2: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score  \n",
    "\n",
    "# Predict train and test targets\n",
    "y_pred_train = rforrest.predict( x_train_pro )   # predict training target\n",
    "y_pred_test = rforrest.predict( x_test_pro )     # predict test target\n",
    "\n",
    "# Print results\n",
    "print('Elastic-Net REGRESSION')\n",
    "print('--------------------------------------')\n",
    "print('Train RMSE: %0.2f' % np.sqrt( MSE(y_train, y_pred_train) ))\n",
    "print('Test RMSE: %0.2f' % np.sqrt( MSE(y_test, y_pred_test) ))\n",
    "print(\"\")\n",
    "print('Train R^2: %0.2f' % r2_score( y_train, y_pred_train ))\n",
    "print('Test R^2: %0.2f' % r2_score( y_test, y_pred_test ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
